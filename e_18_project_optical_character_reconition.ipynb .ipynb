{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "greenhouse-excitement",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-23T04:34:59.589792Z",
     "start_time": "2021-03-23T04:34:59.584812Z"
    }
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "import numpy\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "worth-antarctica",
   "metadata": {},
   "source": [
    "# Step1. 검증용 데이터셋 준비"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "breathing-handbook",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "directed-spell",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "casual-farming",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "mathematical-moment",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "norwegian-eugene",
   "metadata": {},
   "source": [
    "# Step2. Google OCR API, keras-ocr, Tesseract로 테스트 진행"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "proprietary-facility",
   "metadata": {},
   "source": [
    "## Google OCR API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "alternative-creator",
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_text(path):\n",
    "    \"\"\"Detects text in the file.\"\"\"\n",
    "    from google.cloud import vision\n",
    "    import io\n",
    "    client = vision.ImageAnnotatorClient()\n",
    "\n",
    "    with io.open(path, 'rb') as image_file:\n",
    "        content = image_file.read()\n",
    "        \n",
    "    image = vision.Image(content=content)\n",
    "\n",
    "    response = client.text_detection(image=image)\n",
    "    texts = response.text_annotations\n",
    "    print('Texts:')\n",
    "\n",
    "    for text in texts:\n",
    "       print('\\n\"{}\"'.format(text.description))\n",
    "\n",
    "    vertices = (['({},{})'.format(vertex.x, vertex.y)\n",
    "                 for vertex in text.bounding_poly.vertices])\n",
    "\n",
    "    print('bounds: {}'.format(','.join(vertices)))\n",
    "\n",
    "    if response.error.message:\n",
    "        raise Exception(\n",
    "            '{}\\nFor more info on error messages, check: '\n",
    "            'https://cloud.google.com/apis/design/errors'.format(\n",
    "                response.error.message))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "armed-trauma",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 다운받은 인증키 경로가 정확하게 지정되어 있어야 합니다. \n",
    "!ls -l $GOOGLE_APPLICATION_CREDENTIALS\n",
    "\n",
    "import os\n",
    "os.environ[\"GOOGLE_APPLICATION_CREDENTIALS\"] =  os.getenv('HOME')+'/aiffel/ocr_python/my_google_api_key.json'\n",
    "\n",
    "# 입력 이미지 경로를 지정해 주세요.\n",
    "# (예시) path = os.getenv('HOME')+'/aiffel/ocr_python/test_image.png'\n",
    "path = os.getenv('HOME')+'/aiffel/ocr_python/ocr.jpg' # [[YOUR IMAGE FILE PATH]]   \n",
    "\n",
    "# 위에서 정의한 OCR API 이용 함수를 호출해 봅시다.\n",
    "detect_text(path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "designed-adobe",
   "metadata": {},
   "source": [
    "## keras-ocr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "demographic-collector",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import keras_ocr\n",
    "\n",
    "# keras-ocr이 detector과 recognizer를 위한 모델을 자동으로 다운로드받게 됩니다. \n",
    "pipeline = keras_ocr.pipeline.Pipeline()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "varying-mustang",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 테스트에 사용할 이미지 url을 모아 봅니다. 추가로 더 모아볼 수도 있습니다. \n",
    "image_urls = [\n",
    "  'https://source.unsplash.com/M7mu6jXlcns/640x460',\n",
    "  'https://source.unsplash.com/6jsp4iHc8hI/640x460',\n",
    "  'https://source.unsplash.com/98uYQ-KupiE',\n",
    "  'https://source.unsplash.com/j9JoYpaJH3A',\n",
    "  'https://source.unsplash.com/eBkEJ9cH5b4'\n",
    "]\n",
    "\n",
    "images = [ keras_ocr.tools.read(url) for url in image_urls]\n",
    "prediction_groups = [pipeline.recognize([url]) for url in image_urls]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "velvet-canal",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the predictions\n",
    "fig, axs = plt.subplots(nrows=len(images), figsize=(20, 20))\n",
    "for idx, ax in enumerate(axs):\n",
    "    keras_ocr.tools.drawAnnotations(image=images[idx], \n",
    "                                    predictions=prediction_groups[idx][0], ax=ax)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "german-hartford",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "alternative-stadium",
   "metadata": {},
   "source": [
    "## Tesseract"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "married-token",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pytesseract\n",
    "from PIL import Image\n",
    "from pytesseract import Output\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# OCR Engine modes(–oem):\n",
    "# 0 - Legacy engine only.\n",
    "# 1 - Neural nets LSTM engine only.\n",
    "# 2 - Legacy + LSTM engines.\n",
    "# 3 - Default, based on what is available.\n",
    "\n",
    "# Page segmentation modes(–psm):\n",
    "# 0 - Orientation and script detection (OSD) only.\n",
    "# 1 - Automatic page segmentation with OSD.\n",
    "# 2 - Automatic page segmentation, but no OSD, or OCR.\n",
    "# 3 - Fully automatic page segmentation, but no OSD. (Default)\n",
    "# 4 - Assume a single column of text of variable sizes.\n",
    "# 5 - Assume a single uniform block of vertically aligned text.\n",
    "# 6 - Assume a single uniform block of text.\n",
    "# 7 - Treat the image as a single text line.\n",
    "# 8 - Treat the image as a single word.\n",
    "# 9 - Treat the image as a single word in a circle.\n",
    "# 10 - Treat the image as a single character.\n",
    "# 11 - Sparse text. Find as much text as possible in no particular order.\n",
    "# 12 - Sparse text with OSD.\n",
    "# 13 - Raw line. Treat the image as a single text line, bypassing hacks that are Tesseract-specific.\n",
    "\n",
    "def crop_word_regions(image_path='./images/sample.png', output_path='./output'):\n",
    "    if not os.path.exists(output_path):\n",
    "        os.mkdir(output_path)\n",
    "    custom_oem_psm_config = r'--oem 3 --psm 3'\n",
    "    image = Image.open(image_path)\n",
    "\n",
    "    recognized_data = pytesseract.image_to_data(\n",
    "        image, lang='eng',    # 한국어라면 lang='kor'\n",
    "        config=custom_oem_psm_config,\n",
    "        output_type=Output.DICT\n",
    "    )\n",
    "    \n",
    "    top_level = max(recognized_data['level'])\n",
    "    index = 0\n",
    "    cropped_image_path_list = []\n",
    "    for i in range(len(recognized_data['level'])):\n",
    "        level = recognized_data['level'][i]\n",
    "    \n",
    "        if level == top_level:\n",
    "            left = recognized_data['left'][i]\n",
    "            top = recognized_data['top'][i]\n",
    "            width = recognized_data['width'][i]\n",
    "            height = recognized_data['height'][i]\n",
    "            \n",
    "            output_img_path = os.path.join(output_path, f\"{str(index).zfill(4)}.png\")\n",
    "            print(output_img_path)\n",
    "            cropped_image = image.crop((\n",
    "                left,\n",
    "                top,\n",
    "                left+width,\n",
    "                top+height\n",
    "            ))\n",
    "            cropped_image.save(output_img_path)\n",
    "            cropped_image_path_list.append(output_img_path)\n",
    "            index += 1\n",
    "    return cropped_image_path_list\n",
    "\n",
    "\n",
    "work_dir = os.getenv('HOME')+'/aiffel/ocr_python'\n",
    "img_file_path = work_dir + '/ocr.jpg'   #테스트용 이미지 경로입니다. 본인이 선택한 파일명으로 바꿔주세요. \n",
    "\n",
    "cropped_image_path_list = crop_word_regions(img_file_path, work_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "previous-kernel",
   "metadata": {},
   "outputs": [],
   "source": [
    "def recognize_images(cropped_image_path_list):\n",
    "    custom_oem_psm_config = r'--oem 3 --psm 7'\n",
    "    \n",
    "    for image_path in cropped_image_path_list:\n",
    "        image = Image.open(image_path)\n",
    "        recognized_data = pytesseract.image_to_string(\n",
    "            image, lang='eng',    # 한국어라면 lang='kor'\n",
    "            config=custom_oem_psm_config,\n",
    "            output_type=Output.DICT\n",
    "        )\n",
    "        print(recognized_data['text'])\n",
    "    print(\"Done\")\n",
    "\n",
    "# 위에서 준비한 문자 영역 파일들을 인식하여 얻어진 텍스트를 출력합니다.\n",
    "recognize_images(cropped_image_path_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "equivalent-planet",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "increased-lighting",
   "metadata": {},
   "source": [
    "# Step3. 테스트 결과 정리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "based-method",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "defensive-nurse",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "industrial-constitution",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "municipal-recording",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "focal-fireplace",
   "metadata": {},
   "source": [
    "# Step4. 결과 분석과 결론 제시"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "separate-anger",
   "metadata": {},
   "source": [
    "## 구현하고자 하는 서비스의 목적"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cardiac-trout",
   "metadata": {},
   "source": [
    "## 평가기준 설정"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "packed-buffer",
   "metadata": {},
   "source": [
    "- 이미지의 확장자와 관계없이 결과가 도출되었는가?\n",
    "- 이미지 상의 언어에 관계없이 결과가 도출되었는가?\n",
    "    - 이미지 상의 언어를 정확하게 Detection 하였는가?\n",
    "    - 이미지 상의 언어를 정확하게 Recognition 하였는가?\n",
    "- 이미지의 상태와 관계없이 결과가 도출되었는가?\n",
    "    - 이미지 상의 흐릿한 언어를 검출하였는가?\n",
    "    - 이미지 상의 가려진 언어를 검출하였는가?\n",
    "    - 이미지 상의 언어 크기에 상관없이 검출하였는가?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "patent-newport",
   "metadata": {},
   "source": [
    "## 테스트 결과 분석 및 모델 선정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "unable-methodology",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "regulated-electric",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "caroline-murder",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "wrong-arabic",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "based-islam",
   "metadata": {},
   "source": [
    "# 루브릭"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "standing-tobago",
   "metadata": {},
   "source": [
    "__1. OCR을 활용하여 구현하려는 서비스의 기획이 타당한가?__  \n",
    "_(목표로 하는 서비스가 OCR를 적용 가능하며, OCR을 활용했을 때 더욱 유용해진다.)_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cloudy-seattle",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "medical-advice",
   "metadata": {},
   "source": [
    "__2. 모델 평가기준이 명확하고 체계적으로 세워졌는가?__  \n",
    "_(평가 기준에 부합하는 테스트 데이터의 특징이 무엇인지 명확하게 제시되었다.)_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sonic-finding",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "underlying-roads",
   "metadata": {},
   "source": [
    "__3. 평가기준에 따라 충분한 분량의 테스트가 진행되고 그 결과가 잘 정리되었는가?__\n",
    "_(최대 20장까지의 테스트 이미지를 사용해 제시된 평가 기준에 따른 테스트 결과가 잘 정리되어 결론이 도출되었다.)_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "surface-sudan",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "electrical-direction",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "periodic-associate",
   "metadata": {},
   "source": [
    "# 회고"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "unlikely-nothing",
   "metadata": {},
   "source": [
    "1. 프로젝트 진행시 어려웠던 점\n",
    "2. 프로젝트를 진행하면서 알아낸 점 또는 아직 모호한 점\n",
    "3. 루브릭 평가 지표를 맞추기 위해 시도한 점\n",
    "4. 루브릭 평가 지표를 달성하지 못한 이유\n",
    "5. 프로젝트 진행 후 느낀 점 및 다짐"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "aiffel",
   "language": "python",
   "name": "aiffel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
